{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Podmanlogo](Pictures/podman-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to kubernetes\n",
    "\n",
    "We already gave a quick explanation of Kubernetes on Podman 101 workshop, here we will go a bit more in depth and explain some core concepts of deploying workloads on Kubernetes. We will not cover architecture, design and infrastructure requirements here; you can check other resources like the kubernetes workshop in HPE Dev platform.\n",
    "\n",
    "To begin with, lets review the official definition of kubernetes out of [its documentation](https://kubernetes.io/docs/concepts/overview/):\n",
    "\n",
    "> Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. It has a large, rapidly growing ecosystem. Kubernetes services, support, and tools are widely available.\n",
    "\n",
    "<img src=\"Pictures/kubernetes-logo.png\" width=\"500\">\n",
    "\n",
    "In practice, kubernetes is a container orchestrator capable of deploying, managing and scale your workloads accross multiple nodes or systems. Compared with Podman, it's design to work in a multi-node environment, being able to deliver high availability of your deployments. There are many other differences in they way both tools work, we'll be looking at some of those during this workshop.\n",
    "\n",
    "As mentioned above kubernetes is a container orchestrator, meaning it can manage your containerized workloads. But enterprises need more than just an orchestrator, they need a whole platform with monitoring, alerting, role based access control, security features, developer tools, etc. The open source community has created some kubernetes distributions that include those additional capabilities that kubernetes doesn't have out of the box. During this workshop we will be using [Red Hat OpenShift](https://www.redhat.com/en/technologies/cloud-computing/openshift), which is a fully open source solution based on the [OKD](https://www.okd.io/) community project. This platform includes everything you may need to use kubernetes in your organization out of the box.\n",
    "\n",
    "![OpenShiftLogo](Pictures/openshift-logo.png)\n",
    "\n",
    "> **Note**: OpenShift uses its own command line tool \"oc\", but as its based on kubernetes you can also use the \"kubectl\" command line tool to interact with the cluster for most of the basic operations. The \"oc\" tool adds the capability of interacting with OpenShift features that are not included with kubernetes out of the box, for this workshop we'll run basic operations so both could be used indistinguibly. As we're used to work with \"oc\" we chose to use this tool for the rest of the workshop.\n",
    "\n",
    "# Kubernetes core concepts\n",
    "\n",
    "Kubernetes uses different entities or objects to manage containerized workloads, in this section we'll review the basic ones. These core concepts are the following:\n",
    "\n",
    " - **Pod**: Pods are the smallest deployable units of computing that you can create and manage in Kubernetes. A Pod is a group of one or more containers, with shared storage and network resources, and a specification for how to run the containers. A Pod's contents are always co-located and co-scheduled, and run in a shared context.\n",
    " - **ReplicaSet**: A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time. As such, it is often used to guarantee the availability of a specified number of identical Pods. By default kubernetes will try to spread replicas across different nodes of the cluster to gain high availability.\n",
    " - **Deployment**: A Deployment provides declarative updates for Pods and ReplicaSets. In other words, is an object that can manage Pods and ReplicaSets and the way they will be updated when a new version of the application is available.\n",
    " - **Service**: a Service is a method for exposing a network application that is running as one or more Pods in your cluster. Fot example, if you have an application with 5 replicas you will not need to remember any ip or dns name for each of those replicas. Instead the Service will act as a network endpoint that, once reached, redirects and load balances the traffic to those endpoints. You could think of it as a forward proxy.\n",
    " - **PersistentVolume (PV)**: is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes.\n",
    " - **Namespaces**: a mechanism for isolating groups of resources within a single cluster. Names of resources need to be unique within a namespace, but not across namespaces. Namespace-based scoping is applicable only for namespaced objects (e.g. Deployments, Services, etc) and not for cluster-wide objects (e.g. StorageClass, Nodes, PersistentVolumes, etc).\n",
    "\n",
    "> **Note**: part of these definitions were taken directly from [the kubernetes documentation](https://kubernetes.io/docs/concepts/workloads/pods/)\n",
    "\n",
    "Lets see this in practice:\n",
    "\n",
    "        CREATE A NAMESPACE, A POD, A REPLICASET, A DEPLOYMENT AND A SERVICE. WIP TO BE FINISHED ONCE THE OPENSHIFT CLUSTER IS DEPLOYED.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
